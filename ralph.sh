#!/bin/bash
set -e

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ralph - Unified AI Coding Agent Runner
# Supports both Claude Code and OpenCode engines
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Get project name from current directory
PROJECT_NAME=$(basename "$(pwd)")

# Config file locations (in priority order)
PROJECT_CONFIG=".ralph/ralph.env"
GLOBAL_CONFIG="$HOME/.config/ralph/ralph.env"

# Log directory and file (external to project)
LOG_DIR="${RALPH_LOG_DIR:-$HOME/.ralph/logs}"
LOG_FILE="$LOG_DIR/ralph-${PROJECT_NAME}.log"

# Progress file location (centralized per-project)
PROGRESS_DIR="$HOME/.ralph/progress"
PROGRESS_FILE="$PROGRESS_DIR/progress-${PROJECT_NAME}.log"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PRESERVE ENVIRONMENT OVERRIDES BEFORE SOURCING CONFIG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ENV_ENGINE=${ENGINE-}
ENV_MAX_ITERATIONS=${MAX_ITERATIONS-}
ENV_SLEEP_SECONDS=${SLEEP_SECONDS-}
ENV_SKIP_COMMIT=${SKIP_COMMIT-}
ENV_PUSH_AFTER_COMMIT=${PUSH_AFTER_COMMIT-}
ENV_MAX_CONSECUTIVE_FAILURES=${MAX_CONSECUTIVE_FAILURES-}

# Claude settings
ENV_CLAUDE_MODEL=${CLAUDE_MODEL-}

# OpenCode settings
ENV_OC_PRIME_MODEL=${OC_PRIME_MODEL-}
ENV_OC_FALL_MODEL=${OC_FALL_MODEL-}

# Test settings
ENV_TEST_CMD=${TEST_CMD-}
ENV_SKIP_TEST_VERIFY=${SKIP_TEST_VERIFY-}

# Rate limit settings
ENV_SOFT_LIMIT_RETRIES=${SOFT_LIMIT_RETRIES-}
ENV_SOFT_LIMIT_WAIT=${SOFT_LIMIT_WAIT-}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DEFAULT CONFIG (for self-healing if global config missing)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

DEFAULT_CONFIG_CONTENT='# Ralph Global Configuration
# Created by ralph.sh (self-healing)
#
# Override per-project: .ralph/ralph.env
# Docs: https://github.com/dominicnunez/ralph

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Engine Selection
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# AI engine: "opencode" or "claude"
ENGINE=opencode

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Model Settings
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# OpenCode primary model (big-pickle is free tier)
OC_PRIME_MODEL=big-pickle

# Claude model (sonnet balances cost/capability)
# Options: opus, sonnet, haiku
CLAUDE_MODEL=sonnet

# OpenCode fallback model when primary hits rate limits (optional)
# OC_FALL_MODEL=

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Iteration Settings
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Maximum iterations (-1 = infinite, run until all tasks complete)
MAX_ITERATIONS=10

# Seconds to pause between iterations
SLEEP_SECONDS=2

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Behavior Settings
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Skip git commits (1 = dont commit, useful for testing)
SKIP_COMMIT=0

# Push after successful commit (1 = push to origin after each commit)
PUSH_AFTER_COMMIT=0

# Skip test verification (1 = dont check for tests, not recommended)
SKIP_TEST_VERIFY=0

# Maximum consecutive failures before stopping (default: 3)
# Only counts failures on the SAME task - resets when task changes
MAX_CONSECUTIVE_FAILURES=3

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Test Settings
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Test command - how Ralph runs your tests after each task
# Auto-detected from: package.json, vitest, jest, pytest, go, cargo
# Set manually if auto-detection fails or you need a custom command
# Examples: "npm run test:ci", "pytest -x", "go test ./... -v"
# TEST_CMD=

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rate Limit Settings (OpenCode only)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Number of retries for soft rate limits (per-minute cooldowns)
# before switching to fallback model
SOFT_LIMIT_RETRIES=3

# Base wait time in seconds for soft rate limit backoff
# Actual wait: base * 2^attempt (30s, 60s, 120s)
SOFT_LIMIT_WAIT=30

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Logging Settings
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Log directory for Ralph session logs
# Default: ~/.ralph/logs
# Logs are named: ralph-<projectname>.log
# RALPH_LOG_DIR=
'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ENSURE GLOBAL CONFIG EXISTS (self-healing)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if [[ ! -f "$GLOBAL_CONFIG" ]]; then
    mkdir -p "$(dirname "$GLOBAL_CONFIG")"
    echo "$DEFAULT_CONFIG_CONTENT" > "$GLOBAL_CONFIG"
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOAD CONFIG FILES (global first, then project overrides)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Load global config
source "$GLOBAL_CONFIG"

# Load project config if exists (overrides global)
if [[ -f "$PROJECT_CONFIG" ]]; then
    source "$PROJECT_CONFIG"
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RESTORE ENVIRONMENT OVERRIDES (env vars take precedence)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

[[ -n "$ENV_ENGINE" ]] && ENGINE="$ENV_ENGINE"
[[ -n "$ENV_MAX_ITERATIONS" ]] && MAX_ITERATIONS="$ENV_MAX_ITERATIONS"
[[ -n "$ENV_SLEEP_SECONDS" ]] && SLEEP_SECONDS="$ENV_SLEEP_SECONDS"
[[ -n "$ENV_SKIP_COMMIT" ]] && SKIP_COMMIT="$ENV_SKIP_COMMIT"
[[ -n "$ENV_PUSH_AFTER_COMMIT" ]] && PUSH_AFTER_COMMIT="$ENV_PUSH_AFTER_COMMIT"
[[ -n "$ENV_MAX_CONSECUTIVE_FAILURES" ]] && MAX_CONSECUTIVE_FAILURES="$ENV_MAX_CONSECUTIVE_FAILURES"
[[ -n "$ENV_CLAUDE_MODEL" ]] && CLAUDE_MODEL="$ENV_CLAUDE_MODEL"
[[ -n "$ENV_OC_PRIME_MODEL" ]] && OC_PRIME_MODEL="$ENV_OC_PRIME_MODEL"
[[ -n "$ENV_OC_FALL_MODEL" ]] && OC_FALL_MODEL="$ENV_OC_FALL_MODEL"
[[ -n "$ENV_TEST_CMD" ]] && TEST_CMD="$ENV_TEST_CMD"
[[ -n "$ENV_SKIP_TEST_VERIFY" ]] && SKIP_TEST_VERIFY="$ENV_SKIP_TEST_VERIFY"
[[ -n "$ENV_SOFT_LIMIT_RETRIES" ]] && SOFT_LIMIT_RETRIES="$ENV_SOFT_LIMIT_RETRIES"
[[ -n "$ENV_SOFT_LIMIT_WAIT" ]] && SOFT_LIMIT_WAIT="$ENV_SOFT_LIMIT_WAIT"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# APPLY SETTINGS (config values already loaded, just set aliases)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MAX=${MAX_ITERATIONS:--1}
SLEEP=${SLEEP_SECONDS:-2}

# Track which model is currently active (for OpenCode fallback)
CURRENT_OC_PRIME_MODEL="$OC_PRIME_MODEL"
USING_FALLBACK=0

COMPLETE_MARKER="<promise>COMPLETE</promise>"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VALIDATE ENGINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

case "$ENGINE" in
    claude|opencode)
        ;;
    *)
        echo "Error: Invalid ENGINE '$ENGINE'. Must be 'claude' or 'opencode'." >&2
        exit 1
        ;;
esac

# Check if the selected engine's CLI is available
if [[ "$ENGINE" == "claude" ]]; then
    if ! command -v claude &>/dev/null; then
        echo "Error: 'claude' command not found. Please install Claude CLI." >&2
        exit 1
    fi
elif [[ "$ENGINE" == "opencode" ]]; then
    if ! command -v opencode &>/dev/null; then
        echo "Error: 'opencode' command not found. Please install OpenCode CLI." >&2
        exit 1
    fi
fi

# Check if PRD.md exists in the current directory
if [[ ! -f "PRD.md" ]]; then
    echo "Error: PRD.md not found in $(pwd)" >&2
    echo "Create a PRD.md file with your project requirements before running Ralph." >&2
    exit 1
fi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OPENCODE AUTO-CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

setup_opencode_permissions() {
    local config_dir="$HOME/.config/opencode"
    local config_file="$config_dir/opencode.json"
    
    # Only needed for opencode engine
    [[ "$ENGINE" != "opencode" ]] && return 0
    
    # Create config dir if needed
    mkdir -p "$config_dir"
    
    # If config doesn't exist, create minimal one with ralph permissions
    if [[ ! -f "$config_file" ]]; then
        cat > "$config_file" << 'EOF'
{
  "$schema": "https://opencode.ai/config.json",
  "permission": {
    "external_directory": {
      "~/.ralph/**": "allow"
    }
  }
}
EOF
        echo "âœ“ Created OpenCode config with Ralph permissions"
        return 0
    fi
    
    # Config exists - check if ralph permission is already there
    if grep -q '\.ralph' "$config_file" 2>/dev/null; then
        return 0  # Already configured
    fi
    
    # Need to add permission to existing config
    # Use jq if available, otherwise warn user
    if command -v jq &>/dev/null; then
        local tmp=$(mktemp)
        jq '.permission.external_directory["~/.ralph/**"] = "allow"' "$config_file" > "$tmp" && mv "$tmp" "$config_file"
        echo "âœ“ Added Ralph permissions to OpenCode config"
    else
        echo "âš ï¸  Please add this to $config_file manually:"
        echo '  "permission": { "external_directory": { "~/.ralph/**": "allow" } }'
    fi
}

# Run OpenCode setup
setup_opencode_permissions

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOGGING FUNCTIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

setup_logging() {
    mkdir -p "$LOG_DIR"
    mkdir -p "$PROGRESS_DIR"
    echo "" >> "$LOG_FILE"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" >> "$LOG_FILE"
    echo "  Ralph Session Started: $(date '+%Y-%m-%d %H:%M:%S')" >> "$LOG_FILE"
    echo "  Project: $PROJECT_NAME" >> "$LOG_FILE"
    echo "  Engine: $ENGINE" >> "$LOG_FILE"
    if [[ "$ENGINE" == "claude" ]]; then
        echo "  Model: $CLAUDE_MODEL" >> "$LOG_FILE"
    else
        echo "  Model: $OC_PRIME_MODEL" >> "$LOG_FILE"
    fi
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" >> "$LOG_FILE"
}

log() {
    local level="$1"
    local message="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] [$level] $message" >> "$LOG_FILE"
    
    # Also print to stdout for certain levels
    case "$level" in
        ERROR|WARN)
            echo "[$level] $message"
            ;;
    esac
}

log_iteration() {
    local iteration="$1"
    local task="$2"
    echo "" >> "$LOG_FILE"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€" >> "$LOG_FILE"
    echo "  Iteration $iteration - $(date '+%H:%M:%S')" >> "$LOG_FILE"
    echo "  Task: $task" >> "$LOG_FILE"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€" >> "$LOG_FILE"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TEST COMMAND DETECTION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

detect_test_cmd() {
    # If explicitly configured, use that
    if [[ -n "$TEST_CMD" ]]; then
        echo "$TEST_CMD"
        return
    fi
    
    # Auto-detect based on project files
    if [[ -f "package.json" ]]; then
        if grep -q '"test"' package.json 2>/dev/null; then
            if [[ -f "bun.lockb" ]]; then
                echo "bun test"
            elif [[ -f "pnpm-lock.yaml" ]]; then
                echo "pnpm test"
            elif [[ -f "yarn.lock" ]]; then
                echo "yarn test"
            else
                echo "npm test"
            fi
            return
        fi
    fi
    
    # Check for common test runners directly
    if [[ -f "vitest.config.ts" ]] || [[ -f "vitest.config.js" ]]; then
        echo "npx vitest run"
        return
    fi
    
    if [[ -f "jest.config.ts" ]] || [[ -f "jest.config.js" ]]; then
        echo "npx jest"
        return
    fi
    
    # Python
    if [[ -f "pytest.ini" ]] || [[ -f "pyproject.toml" ]]; then
        echo "pytest"
        return
    fi
    
    # Go
    if [[ -f "go.mod" ]]; then
        echo "go test ./..."
        return
    fi
    
    # Rust
    if [[ -f "Cargo.toml" ]]; then
        echo "cargo test"
        return
    fi
    
    echo ""
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TEST VERIFICATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

verify_tests_written() {
    # Get the last commit (or staged changes if no commits yet)
    local test_changes=""
    
    # Test file patterns by language:
    # - JS/TS: *.test.ts, *.spec.js, etc.
    # - Python: *_test.py, test_*.py
    # - Go: *_test.go
    local test_pattern='\.(test|spec)\.(ts|js|tsx|jsx|py)$|_test\.(go|py)$|^test_.*\.py$'
    
    # Check for test files in staged/unstaged changes
    test_changes=$(git diff --name-only HEAD 2>/dev/null | grep -E "$test_pattern" || true)
    
    # Also check staged files
    local staged_tests=$(git diff --cached --name-only 2>/dev/null | grep -E "$test_pattern" || true)
    
    # Combine
    if [[ -n "$staged_tests" ]]; then
        test_changes="$test_changes"$'\n'"$staged_tests"
    fi
    
    # Also check for test files in recent commits (in case AI committed)
    local recent_test_commits=$(git diff --name-only HEAD~1 HEAD 2>/dev/null | grep -E "$test_pattern" || true)
    if [[ -n "$recent_test_commits" ]]; then
        test_changes="$test_changes"$'\n'"$recent_test_commits"
    fi
    
    # Remove empty lines and duplicates
    test_changes=$(echo "$test_changes" | grep -v '^$' | sort -u)
    
    if [[ -z "$test_changes" ]]; then
        log "WARN" "No test files were created or modified"
        echo "âŒ No test files were created or modified this iteration"
        return 1
    fi
    
    log "INFO" "Test files changed: $(echo "$test_changes" | tr '\n' ', ')"
    echo "âœ… Test files changed:"
    echo "$test_changes" | sed 's/^/   /'
    return 0
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DIFFERENTIAL TEST VERIFICATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

extract_failing_tests() {
    local test_output="$1"

    # Extract failing test names from common test frameworks
    # Supports: Jest, Vitest, Bun test, pytest, Go test, Mocha, etc.

    # Pattern 1: âœ— test_name or âœ• test_name or FAIL test_name
    # Pattern 2: "test description" (quoted test names)
    # Pattern 3: --- FAIL: TestName
    # Pattern 4: at Context.test_name
    # Pattern 5: FAILED test/path.test.ts > test name

    echo "$test_output" | grep -E '(âœ—|âœ•|FAIL|FAILED|Error:|AssertionError|Expected)' | \
        grep -oE '([a-zA-Z_][a-zA-Z0-9_]*\(\)|"[^"]{5,80}"|[a-zA-Z_][a-zA-Z0-9_]{3,60}|Test[A-Z][a-zA-Z0-9_]+)' | \
        sort -u || true
}

compare_test_failures() {
    local baseline_file="$1"
    local current_output="$2"

    # If no baseline file or empty, all failures are new
    if [[ ! -f "$baseline_file" ]] || [[ ! -s "$baseline_file" ]]; then
        echo "NEW_FAILURES"
        return 1
    fi

    # Read baseline
    local baseline_exit_code
    baseline_exit_code=$(head -1 "$baseline_file")

    # Extract baseline output (skip first line and separator)
    local baseline_output
    baseline_output=$(tail -n +3 "$baseline_file")

    # If baseline passed (exit code 0), any new failure is a regression
    if [[ "$baseline_exit_code" == "0" ]]; then
        echo "NEW_FAILURES"
        return 1
    fi

    # Extract failing tests from both outputs
    local baseline_failures
    local current_failures
    baseline_failures=$(extract_failing_tests "$baseline_output")
    current_failures=$(extract_failing_tests "$current_output")

    # If no failures detected in current output, tests pass
    if [[ -z "$current_failures" ]]; then
        echo "NO_NEW_FAILURES"
        return 0
    fi

    # Check if current failures are a subset of baseline failures
    local new_failure_found=0
    while IFS= read -r test_name; do
        if [[ -n "$test_name" ]] && ! echo "$baseline_failures" | grep -qF "$test_name"; then
            new_failure_found=1
            break
        fi
    done <<< "$current_failures"

    if [[ $new_failure_found -eq 1 ]]; then
        echo "NEW_FAILURES"
        return 1
    else
        echo "NO_NEW_FAILURES"
        return 0
    fi
}

run_tests() {
    local test_cmd="$1"
    
    if [[ -z "$test_cmd" ]]; then
        log "WARN" "No test command detected, skipping verification"
        echo "âš ï¸  No test command detected, skipping verification"
        last_test_output=""
        return 0
    fi
    
    echo ""
    echo "ğŸ§ª Running test verification: $test_cmd"
    echo "-------------------------------------------"
    log "INFO" "Running tests: $test_cmd"
    
    set +e
    local test_output
    test_output=$(eval "$test_cmd" 2>&1)
    local exit_code=$?
    set -e
    
    echo "$test_output"
    echo "-------------------------------------------"

    # Store test output globally for use in fix prompt
    last_test_output="$test_output"

    # Log test output (truncated)
    echo "$test_output" | tail -20 >> "$LOG_FILE"

    if [[ $exit_code -eq 0 ]]; then
        log "INFO" "Tests passed"
        echo "âœ… Tests passed!"
        return 0
    else
        # DIFFERENTIAL VERIFICATION: Compare against baseline
        if [[ -f "$BASELINE_FILE" ]] && [[ -s "$BASELINE_FILE" ]]; then
            echo ""
            echo "ğŸ” Checking for new test failures (differential verification)..."

            if compare_test_failures "$BASELINE_FILE" "$test_output"; then
                log "INFO" "Tests failed but no new failures detected (pre-existing failures only)"
                echo "âœ… No new test failures (pre-existing failures are expected)"
                return 0
            else
                log "ERROR" "New test failures detected (not in baseline)"
                echo "âŒ New test failures detected (exit code: $exit_code)"
                return 1
            fi
        else
            # No baseline, treat as regular failure
            log "ERROR" "Tests failed (exit code: $exit_code) - No baseline available"
            echo "âŒ Tests failed (exit code: $exit_code)"
            return 1
        fi
    fi
}

get_current_task() {
    # Extract the first incomplete task from PRD.md
    if [[ -f "PRD.md" ]]; then
        grep -m1 -E '^\s*-\s*\[ \]' PRD.md 2>/dev/null | sed 's/^\s*-\s*\[ \]\s*//' || echo "unknown"
    else
        echo "unknown"
    fi
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RATE LIMIT HANDLING (OpenCode only)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Hard rate limits: quota exhausted, billing issues - won't recover with waiting
is_hard_rate_limit() {
    local output="$1"
    echo "$output" | grep -qiE 'insufficient_quota|insufficient.balance|exceeded.*(usage.tier|current.quota)|billing.details|not.?included.?in.?(your|plan)'
}

# Soft rate limits: temporary cooldowns - may recover after waiting
is_soft_rate_limit() {
    local output="$1"
    # Must have rate limit indicator but NOT hard limit indicators
    if is_hard_rate_limit "$output"; then
        return 1
    fi
    echo "$output" | grep -qiE 'rate.?limit|statusCode.*429|too.?many.?request|per.?minute|tokens.per.minute|over.?capacity|(^|[^a-z])at.?capacity|retry.?after'
}

# Any rate limit (soft or hard)
is_rate_limited() {
    local output="$1"
    is_hard_rate_limit "$output" || is_soft_rate_limit "$output"
}

switch_to_fallback() {
    if [[ -n "$OC_FALL_MODEL" && "$USING_FALLBACK" -eq 0 ]]; then
        echo ""
        echo "==========================================="
        echo "  Rate limit detected on $CURRENT_OC_PRIME_MODEL"
        echo "  Switching to fallback: $OC_FALL_MODEL"
        echo "==========================================="
        echo ""
        log "WARN" "Rate limit on $CURRENT_OC_PRIME_MODEL, switching to $OC_FALL_MODEL"
        CURRENT_OC_PRIME_MODEL="$OC_FALL_MODEL"
        USING_FALLBACK=1
        return 0
    fi
    return 1
}

# Retry with backoff for soft rate limits
# Returns 0 if retry succeeded, 1 if should give up
handle_soft_rate_limit() {
    local attempt="$1"
    local max_retries="${SOFT_LIMIT_RETRIES:-3}"
    local base_wait="${SOFT_LIMIT_WAIT:-30}"
    
    if [[ "$attempt" -ge "$max_retries" ]]; then
        log "WARN" "Soft rate limit: exhausted $max_retries retries"
        echo "âš ï¸  Soft rate limit persisted after $max_retries retries"
        return 1
    fi
    
    # Exponential backoff: 30s, 60s, 120s
    local wait_time=$((base_wait * (2 ** attempt)))
    
    echo ""
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    echo "  â³ Soft rate limit detected (attempt $((attempt + 1))/$max_retries)"
    echo "  Waiting ${wait_time}s before retry..."
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    log "INFO" "Soft rate limit: waiting ${wait_time}s (attempt $((attempt + 1))/$max_retries)"
    
    sleep "$wait_time"
    return 0
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PROMPT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if [[ "$SKIP_COMMIT" == "1" ]]; then
    COMMIT_INSTRUCTIONS=$(cat <<EOF
- If tests PASS:
  - Update PRD.md to mark the task complete (change [ ] to [x])
  - Do NOT commit any changes in this run
  - Append what worked to $PROGRESS_FILE
EOF
)
else
    COMMIT_INSTRUCTIONS=$(cat <<EOF
- If tests PASS:
  - Update PRD.md to mark the task complete (change [ ] to [x])
  - Commit your changes with message: feat: [task description] (do NOT add Co-Authored-By)
  - Append what worked to $PROGRESS_FILE
EOF
)
fi

PROMPT=$(cat <<EOF
You are Ralph, an autonomous coding agent. Do exactly ONE task per iteration.

## Steps

1. Read PRD.md and find the first task that is NOT complete (marked [ ]).
2. Read $PROGRESS_FILE - check the Learnings section first for patterns from previous iterations.
3. Implement that ONE task only.
4. **CRITICAL: You MUST write tests for your implementation.**
5. **CRITICAL: You MUST run tests and ensure ALL tests pass.**

## Test Requirement (MANDATORY)

You MUST:
- Create or modify a test file (e.g., *.test.ts, *.spec.ts)
- Write at least one test for the feature you implement
- Run the full test suite
- Verify ALL tests pass before marking the task complete

If you do not write tests, the task will be rejected and you must try again.

## Only Complete If Tests Pass

$COMMIT_INSTRUCTIONS

- If tests FAIL:
  - Do NOT mark the task complete
  - Do NOT commit broken code
  - Append what went wrong to $PROGRESS_FILE (so next iteration can learn)

## Progress Notes Format

Append to $PROGRESS_FILE using this format:

## Iteration [N] - [Task Name]
- What was implemented
- Test file created/modified: [filename]
- Tests written: [brief description]
- Test results: PASS/FAIL
- Files changed
- Learnings for future iterations
---

## Update AGENTS.md (If Applicable)

If you discover a reusable pattern that future work should know about:
- Check if AGENTS.md exists in the project root
- Add patterns like: 'This codebase uses X for Y' or 'Always do Z when changing W'
- Only add genuinely reusable knowledge, not task-specific details

## End Condition

After completing your task, check PRD.md:
- If ALL tasks are [x], output exactly: $COMPLETE_MARKER
- If tasks remain [ ], just end your response (next iteration will continue)
EOF
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FIX TESTS PROMPT (used when previous iteration had test failures)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# This will be built dynamically with the actual test output
build_fix_tests_prompt() {
    local test_output="$1"
    local truncated_output
    
    # Truncate test output to last 100 lines to avoid overwhelming the AI
    truncated_output=$(echo "$test_output" | tail -100)
    
    cat <<EOF
You are Ralph, an autonomous coding agent. Your ONLY task is to FIX THE FAILING TESTS.

## PRIORITY: FIX FAILING TESTS

The previous iteration failed because tests did not pass. You MUST fix the failing tests before doing anything else.

## Test Failure Output

\`\`\`
$truncated_output
\`\`\`

## Steps

1. Read the test failure output above carefully.
2. Read $PROGRESS_FILE - check what was attempted and what failed.
3. Identify WHY the tests are failing (look at the error messages).
4. Fix the code or tests to make ALL tests pass.
5. Run the full test suite to verify ALL tests pass.

## Rules

- Do NOT implement new features
- Do NOT mark any tasks complete until tests pass
- Do NOT commit any code until tests pass
- Focus ONLY on making the existing tests pass

## After Fixing

$COMMIT_INSTRUCTIONS

- Append what you fixed to $PROGRESS_FILE with format:

## Fix Attempt - Iteration [N]
- Error identified: [what was wrong]
- Fix applied: [what you changed]
- Test results: PASS/FAIL
---

## End Condition

After fixing and tests pass, check PRD.md:
- If ALL tasks are [x], output exactly: $COMPLETE_MARKER
- If tasks remain [ ], just end your response (next iteration will continue)
EOF
}

# Function to get the appropriate prompt based on test failure mode
get_current_prompt() {
    if [[ "$test_failure_mode" -eq 1 ]] && [[ -n "$last_test_output" ]]; then
        build_fix_tests_prompt "$last_test_output"
    else
        echo "$PROMPT"
    fi
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RUN ENGINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

run_claude() {
    local prompt="$1"
    # Wrap in script for PTY - makes Claude stream output like OpenCode
    script -q /dev/null -c "claude --model \"$CLAUDE_MODEL\" --dangerously-skip-permissions -p \"$prompt\""
}

run_opencode() {
    local prompt="$1"
    # OpenCode requires a PTY to function - script provides a pseudo-TTY wrapper
    # Without this, opencode hangs indefinitely in non-interactive environments
    # (cron, background processes, piped output)
    script -q /dev/null -c "opencode run --model \"$CURRENT_OC_PRIME_MODEL\" \"$prompt\""
}

run_engine() {
    local prompt="$1"
    if [[ "$ENGINE" == "claude" ]]; then
        run_claude "$prompt"
    else
        run_opencode "$prompt"
    fi
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Setup logging
setup_logging

# Detect test command at startup
DETECTED_TEST_CMD=$(detect_test_cmd)

# Print startup info
if [[ "$MAX" -eq -1 ]]; then
    echo "Starting Ralph ($ENGINE) - Infinite mode (until complete)"
else
    echo "Starting Ralph ($ENGINE) - Max $MAX iterations"
fi

if [[ "$ENGINE" == "claude" ]]; then
    echo "Using model: $CLAUDE_MODEL"
else
    echo "Using model: $OC_PRIME_MODEL"
    [[ -n "$OC_FALL_MODEL" ]] && echo "Fallback model: $OC_FALL_MODEL"
fi

[[ "$SKIP_COMMIT" == "1" ]] && echo "Commits disabled for this run"
[[ "$PUSH_AFTER_COMMIT" == "1" ]] && echo "ğŸ“¤ Push after commit: enabled"

if [[ "$SKIP_TEST_VERIFY" == "1" ]]; then
    echo "âš ï¸  Test verification DISABLED"
    log "WARN" "Test verification disabled"
elif [[ -n "$DETECTED_TEST_CMD" ]]; then
    echo "ğŸ§ª Test command: $DETECTED_TEST_CMD"
    log "INFO" "Test command: $DETECTED_TEST_CMD"
else
    echo "âš ï¸  No test command detected (configure TEST_CMD in ralph.env)"
    log "WARN" "No test command detected"
fi

echo "ğŸ“ Log file: $LOG_FILE"
echo ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PRE-FLIGHT TEST BASELINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Temp file to store baseline test failures
BASELINE_FILE=$(mktemp)
trap "rm -f $BASELINE_FILE" EXIT

# Run pre-flight test baseline if tests are enabled
if [[ "$SKIP_TEST_VERIFY" != "1" ]] && [[ -n "$DETECTED_TEST_CMD" ]]; then
    echo "ğŸ” Running pre-flight test baseline..."
    log "INFO" "Running pre-flight test baseline"

    set +e
    baseline_output=$(eval "$DETECTED_TEST_CMD" 2>&1)
    baseline_exit_code=$?
    set -e

    # Store baseline output and exit code
    echo "$baseline_exit_code" > "$BASELINE_FILE"
    echo "---BASELINE-OUTPUT---" >> "$BASELINE_FILE"
    echo "$baseline_output" >> "$BASELINE_FILE"

    if [[ $baseline_exit_code -eq 0 ]]; then
        echo "âœ… Pre-flight baseline: All tests passing"
        log "INFO" "Pre-flight baseline: All tests passing"
    else
        echo "âš ï¸  Pre-flight baseline: Tests failing (exit code: $baseline_exit_code)"
        log "WARN" "Pre-flight baseline: Tests failing (exit code: $baseline_exit_code)"

        # Log to progress file
        echo "" >> "$PROGRESS_FILE"
        echo "## Pre-flight Test Baseline - $(date '+%Y-%m-%d %H:%M:%S')" >> "$PROGRESS_FILE"
        echo "- Exit code: $baseline_exit_code" >> "$PROGRESS_FILE"
        echo "- Status: Pre-existing test failures detected" >> "$PROGRESS_FILE"
        echo "- These failures will not block PRD work (differential verification enabled)" >> "$PROGRESS_FILE"
        echo "" >> "$PROGRESS_FILE"
        echo "### Baseline Test Output (last 50 lines):" >> "$PROGRESS_FILE"
        echo "\`\`\`" >> "$PROGRESS_FILE"
        echo "$baseline_output" | tail -50 >> "$PROGRESS_FILE"
        echo "\`\`\`" >> "$PROGRESS_FILE"
        echo "---" >> "$PROGRESS_FILE"
    fi
    echo ""
fi

i=0
consecutive_failures=0
soft_limit_retries=0
last_failed_task=""
test_failure_mode=0
last_test_output=""

while [[ "$MAX" -eq -1 ]] || [[ "$i" -lt "$MAX" ]]; do
    ((++i))
    
    # Record HEAD before iteration (for push detection)
    head_before=$(git rev-parse HEAD 2>/dev/null || echo "")
    
    current_task=$(get_current_task)
    log_iteration "$i" "$current_task"
    
    # Build display model name
    if [[ "$ENGINE" == "claude" ]]; then
        display_model="$CLAUDE_MODEL"
    else
        display_model="$CURRENT_OC_PRIME_MODEL"
    fi
    
    if [[ "$MAX" -eq -1 ]]; then
        echo "==========================================="
        echo "  Iteration $i (infinite mode) - $display_model"
        echo "  Task: $current_task"
        [[ "$test_failure_mode" -eq 1 ]] && echo "  Mode: ğŸ”§ FIX TESTS"
        echo "==========================================="
    else
        echo "==========================================="
        echo "  Iteration $i of $MAX - $display_model"
        echo "  Task: $current_task"
        [[ "$test_failure_mode" -eq 1 ]] && echo "  Mode: ğŸ”§ FIX TESTS"
        echo "==========================================="
    fi

    # Get the appropriate prompt (normal or fix-tests)
    current_prompt=$(get_current_prompt)
    
    # Run AI agent
    set +e
    tmpfile=$(mktemp)
    run_engine "$current_prompt" 2>&1 | tee "$tmpfile"
    exit_code=${PIPESTATUS[0]}
    result=$(cat "$tmpfile")
    rm -f "$tmpfile"
    set -e
    
    # Log AI output (truncated)
    echo "$result" | head -50 >> "$LOG_FILE"
    echo "[... truncated ...]" >> "$LOG_FILE"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RATE LIMIT HANDLING (OpenCode only)
    # Strategy: hard limits â†’ immediate fallback
    #           soft limits â†’ retry with backoff, then fallback
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    if [[ "$ENGINE" == "opencode" ]]; then
        rate_limit_handled=0
        
        # Check for hard rate limit (quota exhausted) - immediate fallback
        if is_hard_rate_limit "$result"; then
            log "WARN" "Hard rate limit detected (quota/billing)"
            echo "ğŸš« Hard rate limit: quota or billing issue"
            soft_limit_retries=0  # Reset soft counter
            if switch_to_fallback; then
                ((--i))
                rate_limit_handled=1
            else
                log "ERROR" "Hard rate limit and no fallback available"
                echo "âŒ Hard rate limit and no fallback available"
                exit 1
            fi
        # Check for soft rate limit (temporary cooldown) - retry first
        elif is_soft_rate_limit "$result"; then
            log "WARN" "Soft rate limit detected (temporary cooldown)"
            if handle_soft_rate_limit "$soft_limit_retries"; then
                ((soft_limit_retries++))
                ((--i))  # Retry same iteration
                rate_limit_handled=1
            else
                # Retries exhausted, try fallback
                soft_limit_retries=0
                if switch_to_fallback; then
                    ((--i))
                    rate_limit_handled=1
                else
                    log "ERROR" "Soft rate limit persisted, no fallback available"
                    echo "âŒ Rate limit persisted after retries, no fallback available"
                    exit 1
                fi
            fi
        fi
        
        if [[ "$rate_limit_handled" -eq 1 ]]; then
            continue
        fi
        
        # Reset soft limit counter on successful iteration
        soft_limit_retries=0
    fi

    # Handle non-rate-limit errors
    if [[ $exit_code -ne 0 ]]; then
        log "ERROR" "$ENGINE failed with exit code $exit_code"
        echo "Error from $ENGINE (exit code $exit_code)"
        exit $exit_code
    fi

    echo ""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # TEST VERIFICATION GATE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    if [[ "$SKIP_TEST_VERIFY" != "1" ]]; then
        verification_failed=0
        
        # Step 1: Verify tests were written
        if [[ -n "$DETECTED_TEST_CMD" ]]; then
            echo ""
            echo "ğŸ“‹ Checking if tests were written..."
            if ! verify_tests_written; then
                log "WARN" "No tests written, iteration failed"
                verification_failed=1
                
                # Append to progress file so AI knows
                echo "" >> "$PROGRESS_FILE"
                echo "## FAILED - Iteration $i" >> "$PROGRESS_FILE"
                echo "- Reason: No test files were created or modified" >> "$PROGRESS_FILE"
                echo "- You MUST write tests before the task can be completed" >> "$PROGRESS_FILE"
                echo "---" >> "$PROGRESS_FILE"
            fi
        fi
        
        # Step 2: Run tests (only if tests were written or we're checking anyway)
        if [[ $verification_failed -eq 0 ]] && [[ -n "$DETECTED_TEST_CMD" ]]; then
            if ! run_tests "$DETECTED_TEST_CMD"; then
                log "WARN" "Tests failed, iteration failed"
                verification_failed=1
                
                # Set test failure mode so next iteration uses fix prompt
                test_failure_mode=1
                
                # Truncate test output for progress file (last 50 lines)
                local truncated_test_output
                truncated_test_output=$(echo "$last_test_output" | tail -50)
                
                # Append to progress file with actual test output
                echo "" >> "$PROGRESS_FILE"
                echo "## FAILED - Iteration $i" >> "$PROGRESS_FILE"
                echo "- Reason: Tests failed" >> "$PROGRESS_FILE"
                echo "- Fix the failing tests before marking the task complete" >> "$PROGRESS_FILE"
                echo "" >> "$PROGRESS_FILE"
                echo "### Test Output (last 50 lines):" >> "$PROGRESS_FILE"
                echo "\`\`\`" >> "$PROGRESS_FILE"
                echo "$truncated_test_output" >> "$PROGRESS_FILE"
                echo "\`\`\`" >> "$PROGRESS_FILE"
                echo "---" >> "$PROGRESS_FILE"
            fi
        fi
        
        # Handle verification failure
        if [[ $verification_failed -eq 1 ]]; then
            # Only increment if same task is failing
            if [[ "$current_task" != "$last_failed_task" ]]; then
                consecutive_failures=1
                last_failed_task="$current_task"
                log "INFO" "Task changed, resetting failure counter"
            else
                ((consecutive_failures++))
            fi
            
            echo ""
            echo "âš ï¸  Verification failed ($consecutive_failures/$MAX_CONSECUTIVE_FAILURES)"
            log "WARN" "Consecutive failures on task '$current_task': $consecutive_failures"
            
            if [[ $consecutive_failures -ge $MAX_CONSECUTIVE_FAILURES ]]; then
                log "ERROR" "Too many consecutive failures on task '$current_task', stopping"
                echo "âŒ Too many consecutive failures on this task"
                echo "   Manual intervention required"
                echo "   Check log: $LOG_FILE"
                exit 1
            fi
            
            echo "   Continuing to next iteration to fix..."
            echo "   ğŸ”§ Next iteration will use fix-tests prompt with test output"
            sleep "$SLEEP"
            continue
        fi
        
        # Reset failure counter and test failure mode on success
        consecutive_failures=0
        last_failed_task=""
        test_failure_mode=0
        last_test_output=""
        log "INFO" "Verification passed"
    fi

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PUSH AFTER COMMIT (if enabled)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    if [[ "$PUSH_AFTER_COMMIT" == "1" ]] && [[ "$SKIP_COMMIT" != "1" ]]; then
        head_after=$(git rev-parse HEAD 2>/dev/null || echo "")
        if [[ -n "$head_before" ]] && [[ "$head_before" != "$head_after" ]]; then
            log "INFO" "New commit detected, pushing to origin"
            echo "ğŸ“¤ Pushing changes to origin..."
            
            # Get current branch
            current_branch=$(git rev-parse --abbrev-ref HEAD 2>/dev/null)
            
            # Check if branch has upstream
            if git rev-parse --abbrev-ref --symbolic-full-name @{u} >/dev/null 2>&1; then
                # Has upstream, simple push
                if git push 2>&1; then
                    log "INFO" "Push successful"
                    echo "âœ… Pushed to origin/$current_branch"
                else
                    log "WARN" "Push failed (will retry next iteration)"
                    echo "âš ï¸  Push failed (will retry next iteration)"
                fi
            else
                # No upstream, push with -u
                if git push -u origin "$current_branch" 2>&1; then
                    log "INFO" "Push successful (set upstream)"
                    echo "âœ… Pushed to origin/$current_branch (set upstream)"
                else
                    log "WARN" "Push failed (will retry next iteration)"
                    echo "âš ï¸  Push failed (will retry next iteration)"
                fi
            fi
        fi
    fi

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # COMPLETION CHECK
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    if [[ "$result" == *"$COMPLETE_MARKER"* ]]; then
        # Verify 1: Check PRD.md for incomplete tasks
        if [[ -f "PRD.md" ]]; then
            incomplete_count=$(grep -cE '^\s*-\s*\[ \]' PRD.md 2>/dev/null || true)
            if [[ "$incomplete_count" -gt 0 ]]; then
                echo ""
                echo "==========================================="
                echo "  âš ï¸  AI claimed complete but $incomplete_count tasks remain"
                echo "  Continuing to next iteration..."
                echo "==========================================="
                log "WARN" "AI claimed complete but $incomplete_count tasks remain"
                sleep "$SLEEP"
                continue
            fi
        fi
        
        # Verify 2: Final test run
        if [[ "$SKIP_TEST_VERIFY" != "1" ]] && [[ -n "$DETECTED_TEST_CMD" ]]; then
            echo ""
            echo "ğŸ”’ Final verification: running full test suite..."
            log "INFO" "Final test verification"
            if ! run_tests "$DETECTED_TEST_CMD"; then
                echo ""
                echo "==========================================="
                echo "  âŒ Final tests failed!"
                echo "  Continuing to fix..."
                echo "==========================================="
                log "ERROR" "Final verification failed"
                sleep "$SLEEP"
                continue
            fi
        fi
        
        log "INFO" "All tasks completed successfully!"
        
        # Archive completed PRD
        if [[ -f "PRD.md" ]]; then
            mkdir -p completed-prds
            timestamp=$(date +%Y%m%d-%H%M%S)
            # Try to extract title from PRD for meaningful filename
            title=$(head -1 PRD.md | sed 's/^#\s*//' | awk '{print $1, $2, $3}' | tr '[:upper:]' '[:lower:]' | tr ' ' '-' | tr -cd '[:alnum:]-' | sed 's/--*/-/g')
            if [[ -n "$title" ]]; then
                archive_name="${timestamp}-${title}.md"
            else
                archive_name="${timestamp}-prd.md"
            fi
            mv PRD.md "completed-prds/${archive_name}"
            log "INFO" "Archived PRD to completed-prds/${archive_name}"
            echo "  ğŸ“ Archived: completed-prds/${archive_name}"
        fi
        
        echo "==========================================="
        echo "  âœ… All tasks complete after $i iterations!"
        echo "  âœ… All tests passing!"
        echo "  ğŸ“ Log: $LOG_FILE"
        echo "==========================================="
        exit 0
    fi

    sleep "$SLEEP"
done

log "WARN" "Reached max iterations ($MAX)"
echo "==========================================="
echo "  Reached max iterations ($MAX)"
echo "  ğŸ“ Log: $LOG_FILE"
echo "==========================================="
exit 1
